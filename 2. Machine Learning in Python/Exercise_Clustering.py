
##Exercise: Clustering
#Applied Data Analytics and Machine Learning in Python

##In this exercise, you will use the python library sklearn to implement clustering using different
#algorithms. The data will be randomly generated by sklearn. You also need to visualize the
#clustering result.
#Further instructions for this task are given in Exercise_Clustering_Template.py.
#After completing the task, you can try change the hyperparameters to observe their impact
#on data generation and classification results from sklearn.datasets import make_blobs

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.datasets import make_blobs

N_SAMPLES = 1000 # wee have 1000 (instead of 10000 how in tamplate) samples because we have 1000 points in the dataset from make_blobs
N_CLUSTERS = 4
CLUSTER_STD = .9
RANDOM_STATE = 0 # RANDOM_STATE ensures reproducibility by fixing the random seed.  
# If set, the same dataset will be generated every time the code runs.


def kmeans(dataset):
    # Input:
    #   - dataset: array, dim(1000, 2)
    # Return:
    #   - labels: array of ints, dim(1000, )
    # Function:
    #   - Perform clustering using KMeans() and return the generated labels

    ### Enter your code here ###
    kmeans_model = KMeans(n_clusters=4, random_state=0)  # Define KMeans with 4 clusters
    kmeans_model.fit(dataset)  # Fit the model to the dataset
    labels = kmeans_model.labels_  # Extract cluster labels


    ### End of your code ###

    return labels


def hierarchical_clustering(dataset):
    # Input:
    #   - dataset: array, dim(1000, 2)
    # Return:
    #   - labels: array of ints, dim(1000, )
    # Function:
    #   - Perform clustering using AgglomerativeClustering() and return the generated labels

    ## Enter your code here ###
    
    # Define the AgglomerativeClustering model with 4 clusters
    clustering_model = AgglomerativeClustering(n_clusters=4)

    # Fit the model and get cluster labels
    labels = clustering_model.fit_predict(dataset)


    ### End of your code ###

    return labels


if __name__ == "__main__": #is a common Python construct used to determine whether a script is being run 
    #as the main program or if it is being imported as a module into another script.
    
    # Function:
    #   - Create a dataset using the global variables defined at the top of the code
    #   - save the points of the dataset in X and the corresponding labels in y_pred
    
    #   - Create a list labels
    #   - The list consists of 3 tuples containing an array with labels and the name of the algorithm
    #     that created the labels:
    #       - 'Ground Truth': original labels of the dataset
    #       - 'KMeans': labels generated by function kmeans()
    #       - 'Hierarchical Clustering': labels generated by function hierarchical_clustering()
    
    #   - The different clusters are plotted (already done). Look for points with different labels
    
    #   - Change the parameters for the generation of the dataset and have a look how the algorithms perform
    #(You can modify the parameters at the top (N_SAMPLES, N_CLUSTERS, CLUSTER_STD) and observe how they affect clustering performance.)

    ### Enter your code here ###

    # Generate dataset using the global variables defined at the top of the code
    X, y_true = make_blobs(n_samples=N_SAMPLES, centers=N_CLUSTERS, cluster_std=CLUSTER_STD, random_state=RANDOM_STATE)
    print(X.shape) #make_blobs() is a function from sklearn.datasets used to generate synthetic clustered data.

    # Apply clustering algorithms
    y_kmeans = kmeans(X)
    y_hierarchical = hierarchical_clustering(X)

    # Create a list labels. Store results in a list
    labels = [
        (y_true, "Ground Truth"),
        (y_kmeans, "KMeans"),
        (y_hierarchical, "Hierarchical Clustering")
    ]

    # Plot results
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    for ax, (labels, title) in zip(axes, labels):
        ax.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', edgecolor='k')
        ax.set_title(title)
    plt.show()

    ### End of your code ###

    #This code visualizes clusters using a different approach from scatter(). 
    #Instead of plotting all points at once, it plots each cluster separately in a loop.
    
    for labels_k in labels:
        for idx in range(max(labels_k[0]) + 1):
            plt.plot(X[labels_k[0] == idx][:, 0], X[labels_k[0] == idx][:, 1], '.', ms=2, 
                     label='Cluster {:.0f}'.format(idx + 1)) #Names each cluster as "Cluster 1", "Cluster 2", etc.
            plt.title(labels_k[1]) # Set the title of the plot to the algorithm's name
        pass
        plt.show()

        
